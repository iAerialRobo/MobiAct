/home/zhangnb/miniconda3/bin/conda run -n videoWork --no-capture-output python /home/zhangnb/videoUAV/videoWork/lightWeightVideo/testTimeCompare.py
/home/zhangnb/videoUAV/videoWork/models/build_models.py:358: UserWarning: Overwriting mobilenetv4_hybrid_medium in registry with models.build_models.mobilenetv4_hybrid_medium. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  def mobilenetv4_hybrid_medium(pretrained=False, pretrained_cfg=None, pretrained_cfg_overlay=None, **kwargs):
/home/zhangnb/videoUAV/videoWork/models/build_models.py:364: UserWarning: Overwriting mobilenetv4_hybrid_large in registry with models.build_models.mobilenetv4_hybrid_large. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  def mobilenetv4_hybrid_large(pretrained=False, pretrained_cfg=None, pretrained_cfg_overlay=None, **kwargs):
Device --> cuda

=== Measuring inference time for I3D ===
Loaded weights from /home/zhangnb/videoUAV/videoWork/models/i3d_rgb_only_model.pth
Inference time for batch:   0%|                          | 0/60 [00:00<?, ?it/s]Input shapes: [torch.Size([6, 3, 30, 224, 224])]
Inference time for batch:   2%|▎                 | 1/60 [00:01<01:53,  1.92s/it]Input shapes: [torch.Size([6, 3, 30, 224, 224])]
Inference time for batch:   3%|▌                 | 2/60 [00:03<01:32,  1.59s/it]Input shapes: [torch.Size([6, 3, 30, 224, 224])]
Inference time for batch:   5%|▉                 | 3/60 [00:04<01:24,  1.48s/it]Input shapes: [torch.Size([6, 3, 30, 224, 224])]
Inference time for batch:   7%|█▏                | 4/60 [00:05<01:19,  1.42s/it]Input shapes: [torch.Size([6, 3, 30, 224, 224])]
Inference time for batch:   8%|█▌                | 5/60 [00:07<01:17,  1.40s/it]Input shapes: [torch.Size([6, 3, 30, 224, 224])]
Inference time for batch:  10%|█▊                | 6/60 [00:08<01:14,  1.38s/it]Input shapes: [torch.Size([6, 3, 30, 224, 224])]
Inference time for batch:  12%|██                | 7/60 [00:10<01:13,  1.38s/it]Input shapes: [torch.Size([6, 3, 30, 224, 224])]
Inference time for batch:  13%|██▍               | 8/60 [00:11<01:10,  1.36s/it]Input shapes: [torch.Size([6, 3, 30, 224, 224])]
Inference time for batch:  15%|██▋               | 9/60 [00:12<01:09,  1.37s/it]Input shapes: [torch.Size([6, 3, 30, 224, 224])]
Inference time for batch:  17%|██▊              | 10/60 [00:14<01:07,  1.36s/it]Input shapes: [torch.Size([6, 3, 30, 224, 224])]
Inference time for batch:  18%|███              | 11/60 [00:15<01:06,  1.36s/it]Input shapes: [torch.Size([6, 3, 30, 224, 224])]
Inference time for batch:  20%|███▍             | 12/60 [00:16<01:04,  1.35s/it]Input shapes: [torch.Size([6, 3, 30, 224, 224])]
Inference time for batch:  22%|███▋             | 13/60 [00:18<01:05,  1.39s/it]Input shapes: [torch.Size([6, 3, 30, 224, 224])]
Inference time for batch:  23%|███▉             | 14/60 [00:19<01:03,  1.38s/it]Input shapes: [torch.Size([6, 3, 30, 224, 224])]
Inference time for batch:  25%|████▎            | 15/60 [00:20<01:01,  1.38s/it]Input shapes: [torch.Size([6, 3, 30, 224, 224])]
Inference time for batch:  27%|████▌            | 16/60 [00:22<01:00,  1.37s/it]Input shapes: [torch.Size([6, 3, 30, 224, 224])]
Inference time for batch:  28%|████▊            | 17/60 [00:23<00:58,  1.36s/it]Input shapes: [torch.Size([6, 3, 30, 224, 224])]
Inference time for batch:  30%|█████            | 18/60 [00:25<00:57,  1.36s/it]Input shapes: [torch.Size([6, 3, 30, 224, 224])]
Inference time for batch:  32%|█████▍           | 19/60 [00:26<00:55,  1.35s/it]Input shapes: [torch.Size([6, 3, 30, 224, 224])]
Inference time for batch:  33%|█████▋           | 20/60 [00:27<00:54,  1.36s/it]Input shapes: [torch.Size([6, 3, 30, 224, 224])]
Inference time for batch:  35%|█████▉           | 21/60 [00:29<00:52,  1.36s/it]Input shapes: [torch.Size([6, 3, 30, 224, 224])]
Inference time for batch:  37%|██████▏          | 22/60 [00:30<00:51,  1.36s/it]Input shapes: [torch.Size([6, 3, 30, 224, 224])]
Inference time for batch:  38%|██████▌          | 23/60 [00:31<00:50,  1.36s/it]Input shapes: [torch.Size([6, 3, 30, 224, 224])]
Inference time for batch:  40%|██████▊          | 24/60 [00:33<00:49,  1.36s/it]Input shapes: [torch.Size([6, 3, 30, 224, 224])]
Inference time for batch:  42%|███████          | 25/60 [00:34<00:47,  1.36s/it]Input shapes: [torch.Size([6, 3, 30, 224, 224])]
Inference time for batch:  43%|███████▎         | 26/60 [00:35<00:46,  1.36s/it]Input shapes: [torch.Size([6, 3, 30, 224, 224])]
Inference time for batch:  45%|███████▋         | 27/60 [00:37<00:44,  1.36s/it]Input shapes: [torch.Size([6, 3, 30, 224, 224])]
Inference time for batch:  47%|███████▉         | 28/60 [00:38<00:43,  1.36s/it]Input shapes: [torch.Size([6, 3, 30, 224, 224])]
Inference time for batch:  48%|████████▏        | 29/60 [00:39<00:42,  1.36s/it]Input shapes: [torch.Size([6, 3, 30, 224, 224])]
Inference time for batch:  50%|████████▌        | 30/60 [00:41<00:40,  1.35s/it]Input shapes: [torch.Size([6, 3, 30, 224, 224])]
Inference time for batch:  52%|████████▊        | 31/60 [00:42<00:39,  1.36s/it]Input shapes: [torch.Size([6, 3, 30, 224, 224])]
Inference time for batch:  53%|█████████        | 32/60 [00:44<00:37,  1.36s/it]Input shapes: [torch.Size([6, 3, 30, 224, 224])]
Inference time for batch:  55%|█████████▎       | 33/60 [00:45<00:36,  1.35s/it]Input shapes: [torch.Size([6, 3, 30, 224, 224])]
Inference time for batch:  57%|█████████▋       | 34/60 [00:46<00:35,  1.35s/it]Input shapes: [torch.Size([6, 3, 30, 224, 224])]
Inference time for batch:  58%|█████████▉       | 35/60 [00:48<00:33,  1.35s/it]Input shapes: [torch.Size([6, 3, 30, 224, 224])]
Inference time for batch:  60%|██████████▏      | 36/60 [00:49<00:32,  1.36s/it]Input shapes: [torch.Size([6, 3, 30, 224, 224])]
Inference time for batch:  62%|██████████▍      | 37/60 [00:50<00:31,  1.35s/it]Input shapes: [torch.Size([6, 3, 30, 224, 224])]
Inference time for batch:  63%|██████████▊      | 38/60 [00:52<00:29,  1.35s/it]Input shapes: [torch.Size([6, 3, 30, 224, 224])]
Inference time for batch:  65%|███████████      | 39/60 [00:53<00:28,  1.36s/it]Input shapes: [torch.Size([6, 3, 30, 224, 224])]
Inference time for batch:  67%|███████████▎     | 40/60 [00:54<00:27,  1.36s/it]Input shapes: [torch.Size([6, 3, 30, 224, 224])]
Inference time for batch:  68%|███████████▌     | 41/60 [00:56<00:25,  1.36s/it]Input shapes: [torch.Size([6, 3, 30, 224, 224])]
Inference time for batch:  70%|███████████▉     | 42/60 [00:57<00:24,  1.37s/it]Input shapes: [torch.Size([6, 3, 30, 224, 224])]
Inference time for batch:  72%|████████████▏    | 43/60 [00:58<00:23,  1.36s/it]Input shapes: [torch.Size([6, 3, 30, 224, 224])]
Inference time for batch:  73%|████████████▍    | 44/60 [01:00<00:21,  1.36s/it]Input shapes: [torch.Size([6, 3, 30, 224, 224])]
Inference time for batch:  75%|████████████▊    | 45/60 [01:01<00:20,  1.36s/it]Input shapes: [torch.Size([6, 3, 30, 224, 224])]
Inference time for batch:  77%|█████████████    | 46/60 [01:03<00:18,  1.35s/it]Input shapes: [torch.Size([6, 3, 30, 224, 224])]
Inference time for batch:  78%|█████████████▎   | 47/60 [01:04<00:17,  1.36s/it]Input shapes: [torch.Size([6, 3, 30, 224, 224])]
Inference time for batch:  80%|█████████████▌   | 48/60 [01:05<00:16,  1.36s/it]Input shapes: [torch.Size([6, 3, 30, 224, 224])]
Inference time for batch:  82%|█████████████▉   | 49/60 [01:07<00:15,  1.37s/it]Input shapes: [torch.Size([6, 3, 30, 224, 224])]
Inference time for batch:  83%|██████████████▏  | 50/60 [01:08<00:13,  1.37s/it]Input shapes: [torch.Size([6, 3, 30, 224, 224])]
Inference time for batch:  85%|██████████████▍  | 51/60 [01:09<00:12,  1.37s/it]Input shapes: [torch.Size([6, 3, 30, 224, 224])]
Inference time for batch:  87%|██████████████▋  | 52/60 [01:11<00:10,  1.36s/it]Input shapes: [torch.Size([6, 3, 30, 224, 224])]
Inference time for batch:  88%|███████████████  | 53/60 [01:12<00:09,  1.37s/it]Input shapes: [torch.Size([6, 3, 30, 224, 224])]
Inference time for batch:  90%|███████████████▎ | 54/60 [01:13<00:08,  1.37s/it]Input shapes: [torch.Size([6, 3, 30, 224, 224])]
Inference time for batch:  92%|███████████████▌ | 55/60 [01:15<00:06,  1.37s/it]Input shapes: [torch.Size([6, 3, 30, 224, 224])]
Inference time for batch:  93%|███████████████▊ | 56/60 [01:16<00:05,  1.36s/it]Input shapes: [torch.Size([6, 3, 30, 224, 224])]
Inference time for batch:  95%|████████████████▏| 57/60 [01:18<00:04,  1.36s/it]Input shapes: [torch.Size([6, 3, 30, 224, 224])]
Inference time for batch:  97%|████████████████▍| 58/60 [01:19<00:02,  1.36s/it]Input shapes: [torch.Size([6, 3, 30, 224, 224])]
Inference time for batch:  98%|████████████████▋| 59/60 [01:20<00:01,  1.36s/it]Input shapes: [torch.Size([6, 3, 30, 224, 224])]
Inference time for batch: 100%|█████████████████| 60/60 [01:22<00:00,  1.37s/it]
Average inference time per sample for I3D: 20.95 ms

=== Measuring inference time for C3D ===
Loaded weights from /home/zhangnb/videoUAV/videoWork/models/c3d_rgb_only_model.pth
Inference time for batch:   0%|                          | 0/18 [00:00<?, ?it/s]Input shapes: [torch.Size([20, 3, 16, 112, 112])]
Inference time for batch:   6%|█                 | 1/18 [00:01<00:31,  1.85s/it]Input shapes: [torch.Size([20, 3, 16, 112, 112])]
Inference time for batch:  11%|██                | 2/18 [00:03<00:29,  1.84s/it]Input shapes: [torch.Size([20, 3, 16, 112, 112])]
Inference time for batch:  17%|███               | 3/18 [00:05<00:27,  1.84s/it]Input shapes: [torch.Size([20, 3, 16, 112, 112])]
Inference time for batch:  22%|████              | 4/18 [00:07<00:25,  1.85s/it]Input shapes: [torch.Size([20, 3, 16, 112, 112])]
Inference time for batch:  28%|█████             | 5/18 [00:09<00:23,  1.85s/it]Input shapes: [torch.Size([20, 3, 16, 112, 112])]
Inference time for batch:  33%|██████            | 6/18 [00:11<00:22,  1.85s/it]Input shapes: [torch.Size([20, 3, 16, 112, 112])]
Inference time for batch:  39%|███████           | 7/18 [00:12<00:20,  1.84s/it]Input shapes: [torch.Size([20, 3, 16, 112, 112])]
Inference time for batch:  44%|████████          | 8/18 [00:14<00:18,  1.87s/it]Input shapes: [torch.Size([20, 3, 16, 112, 112])]
Inference time for batch:  50%|█████████         | 9/18 [00:16<00:16,  1.86s/it]Input shapes: [torch.Size([20, 3, 16, 112, 112])]
Inference time for batch:  56%|█████████▍       | 10/18 [00:18<00:14,  1.84s/it]Input shapes: [torch.Size([20, 3, 16, 112, 112])]
Inference time for batch:  61%|██████████▍      | 11/18 [00:20<00:12,  1.83s/it]Input shapes: [torch.Size([20, 3, 16, 112, 112])]
Inference time for batch:  67%|███████████▎     | 12/18 [00:22<00:11,  1.84s/it]Input shapes: [torch.Size([20, 3, 16, 112, 112])]
Inference time for batch:  72%|████████████▎    | 13/18 [00:23<00:09,  1.84s/it]Input shapes: [torch.Size([20, 3, 16, 112, 112])]
Inference time for batch:  78%|█████████████▏   | 14/18 [00:25<00:07,  1.83s/it]Input shapes: [torch.Size([20, 3, 16, 112, 112])]
Inference time for batch:  83%|██████████████▏  | 15/18 [00:27<00:05,  1.84s/it]Input shapes: [torch.Size([20, 3, 16, 112, 112])]
Inference time for batch:  89%|███████████████  | 16/18 [00:29<00:03,  1.84s/it]Input shapes: [torch.Size([20, 3, 16, 112, 112])]
Inference time for batch:  94%|████████████████ | 17/18 [00:31<00:01,  1.83s/it]Input shapes: [torch.Size([20, 3, 16, 112, 112])]
Inference time for batch: 100%|█████████████████| 18/18 [00:33<00:00,  1.84s/it]
Average inference time per sample for C3D: 2.41 ms

=== Measuring inference time for Cost ===
Loaded weights from /home/zhangnb/videoUAV/videoWork/models/cost_rgb_only_model.pth
Inference time for batch:   0%|                          | 0/23 [00:00<?, ?it/s]Input shapes: [torch.Size([16, 3, 16, 224, 224])]
Inference time for batch:   4%|▊                 | 1/23 [00:02<00:45,  2.06s/it]Input shapes: [torch.Size([16, 3, 16, 224, 224])]
Inference time for batch:   9%|█▌                | 2/23 [00:04<00:43,  2.05s/it]Input shapes: [torch.Size([16, 3, 16, 224, 224])]
Inference time for batch:  13%|██▎               | 3/23 [00:06<00:40,  2.05s/it]Input shapes: [torch.Size([16, 3, 16, 224, 224])]
Inference time for batch:  17%|███▏              | 4/23 [00:08<00:39,  2.09s/it]Input shapes: [torch.Size([16, 3, 16, 224, 224])]
Inference time for batch:  22%|███▉              | 5/23 [00:10<00:37,  2.06s/it]Input shapes: [torch.Size([16, 3, 16, 224, 224])]
Inference time for batch:  26%|████▋             | 6/23 [00:12<00:34,  2.04s/it]Input shapes: [torch.Size([16, 3, 16, 224, 224])]
Inference time for batch:  30%|█████▍            | 7/23 [00:14<00:32,  2.04s/it]Input shapes: [torch.Size([16, 3, 16, 224, 224])]
Inference time for batch:  35%|██████▎           | 8/23 [00:16<00:30,  2.03s/it]Input shapes: [torch.Size([16, 3, 16, 224, 224])]
Inference time for batch:  39%|███████           | 9/23 [00:18<00:28,  2.03s/it]Input shapes: [torch.Size([16, 3, 16, 224, 224])]
Inference time for batch:  43%|███████▍         | 10/23 [00:20<00:26,  2.03s/it]Input shapes: [torch.Size([16, 3, 16, 224, 224])]
Inference time for batch:  48%|████████▏        | 11/23 [00:22<00:24,  2.02s/it]Input shapes: [torch.Size([16, 3, 16, 224, 224])]
Inference time for batch:  52%|████████▊        | 12/23 [00:24<00:22,  2.04s/it]Input shapes: [torch.Size([16, 3, 16, 224, 224])]
Inference time for batch:  57%|█████████▌       | 13/23 [00:26<00:20,  2.04s/it]Input shapes: [torch.Size([16, 3, 16, 224, 224])]
Inference time for batch:  61%|██████████▎      | 14/23 [00:28<00:18,  2.03s/it]Input shapes: [torch.Size([16, 3, 16, 224, 224])]
Inference time for batch:  65%|███████████      | 15/23 [00:30<00:16,  2.03s/it]Input shapes: [torch.Size([16, 3, 16, 224, 224])]
Inference time for batch:  70%|███████████▊     | 16/23 [00:32<00:14,  2.04s/it]Input shapes: [torch.Size([16, 3, 16, 224, 224])]
Inference time for batch:  74%|████████████▌    | 17/23 [00:34<00:12,  2.04s/it]Input shapes: [torch.Size([16, 3, 16, 224, 224])]
Inference time for batch:  78%|█████████████▎   | 18/23 [00:36<00:10,  2.04s/it]Input shapes: [torch.Size([16, 3, 16, 224, 224])]
Inference time for batch:  83%|██████████████   | 19/23 [00:38<00:08,  2.05s/it]Input shapes: [torch.Size([16, 3, 16, 224, 224])]
Inference time for batch:  87%|██████████████▊  | 20/23 [00:40<00:06,  2.03s/it]Input shapes: [torch.Size([16, 3, 16, 224, 224])]
Inference time for batch:  91%|███████████████▌ | 21/23 [00:42<00:04,  2.03s/it]Input shapes: [torch.Size([16, 3, 16, 224, 224])]
Inference time for batch:  96%|████████████████▎| 22/23 [00:44<00:02,  2.02s/it]Input shapes: [torch.Size([8, 3, 16, 224, 224])]
Inference time for batch: 100%|█████████████████| 23/23 [00:45<00:00,  1.99s/it]
Average inference time per sample for Cost: 16.60 ms

=== Measuring inference time for MultiAlignment ===
Loaded weights from /home/zhangnb/videoUAV/videoWork/models/corrected_multimodal_final_model.pth
Inference time for batch:   0%|                          | 0/18 [00:00<?, ?it/s]Input shapes: [torch.Size([20, 3, 30, 128, 128]), torch.Size([20, 3, 30, 128, 128]), torch.Size([20, 3, 30, 128, 128])]
Inference time for batch:   6%|█                 | 1/18 [00:09<02:48,  9.93s/it]Input shapes: [torch.Size([20, 3, 30, 128, 128]), torch.Size([20, 3, 30, 128, 128]), torch.Size([20, 3, 30, 128, 128])]
Inference time for batch:  11%|██                | 2/18 [00:20<02:45, 10.37s/it]Input shapes: [torch.Size([20, 3, 30, 128, 128]), torch.Size([20, 3, 30, 128, 128]), torch.Size([20, 3, 30, 128, 128])]
Inference time for batch:  17%|███               | 3/18 [00:31<02:37, 10.51s/it]Input shapes: [torch.Size([20, 3, 30, 128, 128]), torch.Size([20, 3, 30, 128, 128]), torch.Size([20, 3, 30, 128, 128])]
Inference time for batch:  22%|████              | 4/18 [00:41<02:27, 10.55s/it]Input shapes: [torch.Size([20, 3, 30, 128, 128]), torch.Size([20, 3, 30, 128, 128]), torch.Size([20, 3, 30, 128, 128])]
Inference time for batch:  28%|█████             | 5/18 [00:52<02:17, 10.57s/it]Input shapes: [torch.Size([20, 3, 30, 128, 128]), torch.Size([20, 3, 30, 128, 128]), torch.Size([20, 3, 30, 128, 128])]
Inference time for batch:  33%|██████            | 6/18 [01:03<02:06, 10.58s/it]Input shapes: [torch.Size([20, 3, 30, 128, 128]), torch.Size([20, 3, 30, 128, 128]), torch.Size([20, 3, 30, 128, 128])]
Inference time for batch:  39%|███████           | 7/18 [01:13<01:56, 10.57s/it]Input shapes: [torch.Size([20, 3, 30, 128, 128]), torch.Size([20, 3, 30, 128, 128]), torch.Size([20, 3, 30, 128, 128])]
Inference time for batch:  44%|████████          | 8/18 [01:24<01:45, 10.56s/it]Input shapes: [torch.Size([20, 3, 30, 128, 128]), torch.Size([20, 3, 30, 128, 128]), torch.Size([20, 3, 30, 128, 128])]
Inference time for batch:  50%|█████████         | 9/18 [01:34<01:35, 10.56s/it]Input shapes: [torch.Size([20, 3, 30, 128, 128]), torch.Size([20, 3, 30, 128, 128]), torch.Size([20, 3, 30, 128, 128])]
Inference time for batch:  56%|█████████▍       | 10/18 [01:45<01:24, 10.55s/it]Input shapes: [torch.Size([20, 3, 30, 128, 128]), torch.Size([20, 3, 30, 128, 128]), torch.Size([20, 3, 30, 128, 128])]
Inference time for batch:  61%|██████████▍      | 11/18 [01:55<01:13, 10.56s/it]Input shapes: [torch.Size([20, 3, 30, 128, 128]), torch.Size([20, 3, 30, 128, 128]), torch.Size([20, 3, 30, 128, 128])]
Inference time for batch:  67%|███████████▎     | 12/18 [02:06<01:03, 10.57s/it]Input shapes: [torch.Size([20, 3, 30, 128, 128]), torch.Size([20, 3, 30, 128, 128]), torch.Size([20, 3, 30, 128, 128])]
Inference time for batch:  72%|████████████▎    | 13/18 [02:17<00:52, 10.57s/it]Input shapes: [torch.Size([20, 3, 30, 128, 128]), torch.Size([20, 3, 30, 128, 128]), torch.Size([20, 3, 30, 128, 128])]
Inference time for batch:  78%|█████████████▏   | 14/18 [02:27<00:42, 10.56s/it]Input shapes: [torch.Size([20, 3, 30, 128, 128]), torch.Size([20, 3, 30, 128, 128]), torch.Size([20, 3, 30, 128, 128])]
Inference time for batch:  83%|██████████████▏  | 15/18 [02:38<00:31, 10.57s/it]Input shapes: [torch.Size([20, 3, 30, 128, 128]), torch.Size([20, 3, 30, 128, 128]), torch.Size([20, 3, 30, 128, 128])]
Inference time for batch:  89%|███████████████  | 16/18 [02:48<00:21, 10.57s/it]Input shapes: [torch.Size([20, 3, 30, 128, 128]), torch.Size([20, 3, 30, 128, 128]), torch.Size([20, 3, 30, 128, 128])]
Inference time for batch:  94%|████████████████ | 17/18 [02:59<00:10, 10.56s/it]Input shapes: [torch.Size([20, 3, 30, 128, 128]), torch.Size([20, 3, 30, 128, 128]), torch.Size([20, 3, 30, 128, 128])]
Inference time for batch: 100%|█████████████████| 18/18 [03:10<00:00, 10.56s/it]
Average inference time per sample for MultiAlignment: 9.61 ms

=== Measuring inference time for MobileNetV4 ===
Error loading weights for MobileNetV4 from /home/zhangnb/videoUAV/videoWork/models/multimodal_final_model.pth: [Errno 2] No such file or directory: '/home/zhangnb/videoUAV/videoWork/models/multimodal_final_model.pth'

=== Inference Time Results (per Sample) ===
            Model  ...  Batch Size
0             I3D  ...           6
1             C3D  ...          20
2            Cost  ...          16
3  MultiAlignment  ...          20

[4 rows x 5 columns]

Results saved to 'inference_times_per_sample.csv' and 'inference_times_per_sample.png'

Process finished with exit code 0


mobileNetV4:
Final Test Evaluation:
/home/zhangnb/miniconda3/envs/videoWork/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Test Loss: 1.9309, Accuracy: 23.06%, F1: 0.0937, Precision: 0.0576, Recall: 0.2500
Average Inference Time per Sample: 1.3994 ms
/home/zhangnb/miniconda3/envs/videoWork/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
===========================================================================